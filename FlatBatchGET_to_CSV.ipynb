{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38795880",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Flat Batch GET to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293def63",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91f5e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "import requests\n",
    "import time\n",
    "import pandas as pd \n",
    "import json \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1656a2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_runtime =boto3.client(\n",
    "    service_name=\"s3\",\n",
    "    region_name =\"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ce06671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-25 16:09:07 athena-test-query-results12\r\n",
      "2023-04-21 16:10:57 google-maps-places-123\r\n",
      "2023-04-24 16:32:01 gplaces12345\r\n",
      "2023-11-06 10:43:06 itv-flights-st\r\n",
      "2023-10-23 22:05:13 itv-github-st\r\n",
      "2023-12-19 15:56:09 particle-flat-demo\r\n",
      "2023-07-09 21:31:59 sangyet-resume-page\r\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4449b2e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0213a941",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Retrieve Boost Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "760aefc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collect_boost_data(base_url, jwt, query_id, dataset_params = ''):\n",
    "    \"\"\"Retrieve specified Boost Datasets via calling GET boost/collect-data\"\"\"\n",
    "    \n",
    "    #set headers\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": jwt\n",
    "    }\n",
    "    \n",
    "    #make GET request to /boost - if dataset_params are left as None, all datasets will be requested\n",
    "    response = requests.get(base_url + \"/boost/\" + query_id + \"/collect-data\" + dataset_params, headers=headers)\n",
    "    \n",
    "    #if 200 - return boost collect-data output, otherwise raise exception\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Retrieved the Boost Data for QueryID: {query_id} - Status Code: {response.status_code}\")\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(\n",
    "            f\"GET boost/query_id/collect-data failed: {response.status_code}\"\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13651991",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Structure Boost Output into Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efeeee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_boost_output(dataframe_map, boost_output):\n",
    "    \"\"\"Structures each returned Boost Dataset into a Pandas DataFrame and returns a map containing them all\"\"\"\n",
    "\n",
    "    #convert each dataset in the output into its own pandas dataframe and store it to the map with the dataset name as the key\n",
    "    for dataset in boost_output:\n",
    "        try:\n",
    "            dataframe_map[dataset] = dataframe_map[dataset].append(pd.DataFrame.from_records(boost_output[dataset])).reset_index(drop=True)\n",
    "        except KeyError:\n",
    "            dataframe_map[dataset] = pd.DataFrame.from_records(boost_output[dataset])\n",
    "        \n",
    "    #return the map of dataframes\n",
    "    return dataframe_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdeac60-4d82-4f92-bfeb-29f682a32e31",
   "metadata": {},
   "source": [
    "### Read first column if a CSV into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1228421-8b66-438e-b78c-9c009989bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_first_column_to_list(csv_file):\n",
    "    \"\"\"\n",
    "    Open a CSV file and save the content of the first column in a list.\n",
    "\n",
    "    Parameters:\n",
    "        csv_file (str): The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing the content of the first column.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        column_data = df.iloc[:, 0].tolist()\n",
    "        return column_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file '{csv_file}': {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5675b9-b2c7-4219-b297-a22092d4238c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save dataframes to csv and Folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03e363d2-8c0f-4e5f-98b9-df92558f8379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def save_dataframes_to_csv(dataframes, output_folder):\n",
    "    \"\"\"\n",
    "    Save pandas DataFrames as CSV files in a specified folder.\n",
    "\n",
    "    Parameters:\n",
    "        dataframes (list): A list of pandas DataFrames.\n",
    "        output_folder (str): The folder path where the CSV files will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Create the output folder if it does not exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for i, df in enumerate(dataframes):\n",
    "        filename = os.path.join(output_folder, f\"{df}.csv\")\n",
    "        dataframe_map[df].to_csv(filename, index=False)\n",
    "        try:\n",
    "            dataframe_map[df].to_csv(filename, index=False)\n",
    "            print(f\"DataFrame '{df}' SAVED to {output_folder}\")\n",
    "        except Exception as e:\n",
    "            print(f\"....Error saving DataFrame '{df}': {e}, Most likely no data for this queryID\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3876699d-51a8-4e5f-8cc7-887e149b9287",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15d71014-d00f-4a0c-ac8b-fb432ceacf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a request to the auth endpoint with the client id and client secret to recieve the jwt\n",
    "clientId = \"4c5b528f-7833-4295-9e45-043d4777ac60\"\n",
    "clientSecret = '06836067fd63cfad861a69e2cb197cf367baed162f033fe8656d2b51e1e16329da7f3e91e88656ec5753052a959dff22f624e0925707e050997c20457eaae55a'\n",
    "scope = \"projects/5136974a-22ea-4601-8c65-8f0e4dfe8ac2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1b2f6-2af3-41e9-bbd3-1e1224fc4222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e576f6ae-ecdc-42ba-b171-d53c2e7557e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set base url to use for API requests\n",
    "base_url = 'https://sandbox.particlehealth.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eace532-18ea-4c00-86cb-48849eed0c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_queryID_file_name = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d4bfb64-3111-4acf-8e59-f020007cbaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Query_ids = ['833ab9ac-ff12-436c-8a7c-89db15d1afd6']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb47569",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56415796-ffee-4899-bdf3-0a5465022212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "### Auth\n",
    "\n",
    "url = 'https://sandbox.particlehealth.com/auth'\n",
    "headers = {'client-id': clientId, 'client-secret': clientSecret, 'scope': scope}\n",
    "r = requests.get(url, headers=headers)\n",
    "\n",
    "print(r) ## prints the status code\n",
    "jwtSandbox = r.text\n",
    "#print(f'this is the JWT:\\n{jwtSandbox}') ## prints JWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "581dd89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved the Boost Data for QueryID: 833ab9ac-ff12-436c-8a7c-89db15d1afd6 - Status Code: 200\n",
      "DataFrame 'allergies' SAVED to 833ab9ac-ff12-436c-8a7c-89db15d1afd6\n",
      "DataFrame 'composition' SAVED to 833ab9ac-ff12-436c-8a7c-89db15d1afd6\n",
      "DataFrame 'documentReferences' SAVED to 833ab9ac-ff12-436c-8a7c-89db15d1afd6\n",
      "DataFrame 'encounters' SAVED to 833ab9ac-ff12-436c-8a7c-89db15d1afd6\n",
      "DataFrame 'immunizations' SAVED to 833ab9ac-ff12-436c-8a7c-89db15d1afd6\n",
      "DataFrame 'labs' SAVED to 833ab9ac-ff12-436c-8a7c-89db15d1afd6\n",
      "DataFrame 'locations' SAVED to 833ab9ac-ff12-436c-8a7c-89db15d1afd6\n",
      "DataFrame 'medications' SAVED to 833ab9ac-ff12-436c-8a7c-89db15d1afd6\n",
      "DataFrame 'practitioners' SAVED to 833ab9ac-ff12-436c-8a7c-89db15d1afd6\n",
      "DataFrame 'problems' SAVED to 833ab9ac-ff12-436c-8a7c-89db15d1afd6\n",
      "DataFrame 'procedures' SAVED to 833ab9ac-ff12-436c-8a7c-89db15d1afd6\n",
      "DataFrame 'socialHistories' SAVED to 833ab9ac-ff12-436c-8a7c-89db15d1afd6\n",
      "DataFrame 'vitalSigns' SAVED to 833ab9ac-ff12-436c-8a7c-89db15d1afd6\n"
     ]
    }
   ],
   "source": [
    "for q in Query_ids:\n",
    "    boost_output = collect_boost_data(base_url, jwtSandbox, q)\n",
    "    dataframe_map = dict()\n",
    "    structure_boost_output(dataframe_map, boost_output)\n",
    "\n",
    "\n",
    "    # List of DataFrames\n",
    "    dataframes_list = ['allergies'\n",
    "                       ,'composition'\n",
    "                       ,'documentReferences'\n",
    "                       ,'encounters'\n",
    "                       ,'immunizations'\n",
    "                       ,'labs'\n",
    "                       ,'locations'\n",
    "                       ,'medications'\n",
    "                       ,'practitioners'\n",
    "                       ,'problems'\n",
    "                       ,'procedures'\n",
    "                       ,'socialHistories'\n",
    "                       ,'vitalSigns']\n",
    "\n",
    "    # Output folder path\n",
    "    output_folder = q\n",
    "\n",
    "    # Call the function to save DataFrames as CSVs\n",
    "    save_dataframes_to_csv(dataframes_list, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca5c92c-7dbb-48bc-981e-77838c6e59f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
